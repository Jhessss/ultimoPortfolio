<!DOCTYPE html>
<html lang="pt-br">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="7049169.png" type="image/x-icon">
    <title>Portf√≥lio 6 - IA</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/11.2.0/octicons.min.css" integrity="sha256-..." crossorigin="anonymous" />
    <link href="https://fonts.googleapis.com/css2?family=Rubik+Scribble&display=swap" rel="stylesheet">    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>

    <center>
        <ul class="menu">
            <li class="links"><a href="#bio">Aprendizado de m√°quina</a></li>
            <li class="links"><a href="#tipos">Tipos</a></li>
            <li class="links"><a href="#classifica">Classifica√ß√£o e Regress√£o</a></li>
            <li class="links"><a href="#deep">Redes neurais e Deep Learning</a></li>
            <li class="links"><a href="#discussoes">Discuss√µes</a></li>
            <li class="links"><a href="#problemas">Problemas e Projetos</a></li>
            <li class="links"><a href="#referencias">Refer√™ncias</a></li>

        </ul>

    </center>
    <section id="welcome">
        <div class="parallax-inner">
            <h1><br><span id="name">Portf√≥lio 6 - Intelig√™ncia Artificial</span></h1>
            <h2>Aprendizado de M√°quina</h2>
            <img src="WP2-IA000000-07-1024x599-removebg-preview.png" class="profile" />
        </div>

    </section>



    <section id="bio" class="classe" style="margin-top: 100px;">
        <h1>Aprendizado de M√°quina.</h1>
        <div class="line"></div>
        <p style="text-align: justify;"><b>Machine learning √© o uso de algoritmos para organizar dados, reconhecer padr√µes e fazer com que computadores aprendam com esses modelos para gerar insights inteligentes sem a necessidade de pr√©-programa√ß√£o.

            De uma forma mais geral, podemos dizer que machine learning √© a √°rea da ci√™ncia da computa√ß√£o que permite tornar a intelig√™ncia artificial real. 
            
            Os algoritmos de machine learning aprendem a partir dos dados inseridos em si. Assim, as m√°quinas s√£o treinadas para aprender a executar diferentes tarefas de forma aut√¥noma. Logo, ao serem expostas a novos dados, elas se adaptam a partir dos c√°lculos anteriores e os padr√µes se moldam para oferecer respostas confi√°veis.</b></p>

            <img src="image-4.webp" style="width: 700px; margin-top: 50px;">

    </section>

    <section id="tipos" class="classe">
        <h1>Tipos</h1>
        <div class="line"></div>
        <img src="tipos.png" style="width: 800px; margin-bottom: 70px;">
        <p style="text-align: justify;">Na pr√°tica, o Machine Learning possui 3 tipos de varia√ß√µes, que definem diferentes tipos de aprendizado. Eles s√£o:<br><br>
            <b class="maior">Aprendizado Supervisionado</b> <br><br>
            Nesse tipo de aprendizado, os algoritmos s√£o treinados usando um conjunto de dados rotulados, ou seja, cada exemplo de treinamento √© acompanhado de uma resposta correta. O objetivo do algoritmo √© aprender a mapear as entradas para as sa√≠das corretas, de modo que possa fazer previs√µes precisas para novos dados. Exemplos de algoritmos de aprendizado supervisionado incluem regress√£o linear, regress√£o log√≠stica, m√°quinas de suporte vetorial (SVM) e redes neurais.<br><br>
            O aprendizado de m√°quina supervisionado √© uma abordagem na qual o algoritmo √© treinado com um conjunto de dados rotulado, ou seja, dados que incluem pares de entrada e sa√≠da desejada. Nesse contexto, alguns dos algoritmos fundamentais s√£o K-Nearest Neighbors (KNN), Modelos Lineares e Classificadores Bayesianos.<br>

<b>i. K-Nearest Neighbors (KNN):</b><br>

O K-Nearest Neighbors √© um algoritmo simples e intuitivo que se baseia na ideia de que inst√¢ncias semelhantes tendem a existir pr√≥ximas umas das outras. O funcionamento do KNN √© direto: dado um novo ponto de dados, o algoritmo identifica os "k" pontos mais pr√≥ximos no conjunto de treinamento e atribui a classe mais comum entre esses vizinhos ao novo ponto. O KNN √© amplamente utilizado em problemas de classifica√ß√£o e regress√£o, sendo especialmente √∫til em situa√ß√µes onde a estrutura dos dados √© complexa ou n√£o linear.<br>

<b>ii. Modelos Lineares:</b><br>

Os Modelos Lineares constituem uma classe de algoritmos que assume uma rela√ß√£o linear entre as vari√°veis de entrada e a sa√≠da. Em seu formato mais simples, um modelo linear realiza uma combina√ß√£o linear dos atributos de entrada, adiciona um termo de vi√©s (intercept) e produz uma sa√≠da. Este modelo √© particularmente eficaz quando a rela√ß√£o entre as vari√°veis √© aproximadamente linear. Regress√£o Linear e Regress√£o Log√≠stica s√£o exemplos comuns de Modelos Lineares, utilizados para prever valores cont√≠nuos ou realizar classifica√ß√£o bin√°ria, respectivamente.<br>

<b>iii. Classificadores Bayesianos:</b><br>

Os Classificadores Bayesianos s√£o fundamentados no teorema de Bayes e na probabilidade condicional. Esses algoritmos calculam a probabilidade de uma inst√¢ncia pertencer a uma classe espec√≠fica com base na probabilidade das caracter√≠sticas observadas. O Classificador Naive Bayes √© um exemplo proeminente dessa categoria, assumindo a independ√™ncia condicional entre os atributos, simplificando assim o c√°lculo das probabilidades. Essa abordagem √© eficiente e funciona bem em conjuntos de dados de alta dimensionalidade. Os Classificadores Bayesianos s√£o amplamente utilizados em tarefas de classifica√ß√£o, como filtragem de spam e diagn√≥sticos m√©dicos.<br>

Em resumo, esses algoritmos de aprendizado supervisionado oferecem abordagens distintas para lidar com diferentes tipos de dados e cen√°rios. A escolha entre eles depender√° das caracter√≠sticas espec√≠ficas do problema em quest√£o, como a natureza dos dados, a complexidade da rela√ß√£o entre vari√°veis e os requisitos de desempenho do modelo.<br><br>
            
<b class="maior">Aprendizado N√£o Supervisionado</b><br><br>
Nesse caso, os algoritmos s√£o treinados em um conjunto de dados n√£o rotulados, o que significa que n√£o h√° respostas corretas fornecidas. O objetivo √© descobrir padr√µes ou estruturas ocultas nos dados sem a necessidade de r√≥tulos. Os algoritmos de aprendizado n√£o supervisionado s√£o usados para agrupar dados semelhantes (clusteriza√ß√£o) ou reduzir a dimensionalidade dos dados. Esta forma de aprendizado inclui an√°lise de cluster e autoencoders.<br><br>
Os algoritmos de aprendizado n√£o supervisionado exploram a estrutura e padr√µes intr√≠nsecos nos dados sem depender de r√≥tulos pr√©-existentes. Duas abordagens not√°veis nesse dom√≠nio s√£o o K-means Clustering e os Mapas Auto-organiz√°veis (Self-Organizing Maps). <br>

<b>i. K-means Clustering:</b><br>

O K-means √© um dos algoritmos de clustering mais amplamente utilizados. Sua principal tarefa √© agrupar um conjunto de dados em k clusters, onde cada cluster √© representado pelo seu centr√≥ide, que √© a m√©dia dos pontos de dados no cluster. O algoritmo itera entre atribuir pontos ao cluster mais pr√≥ximo e recalcular os centr√≥ides at√© que a converg√™ncia seja alcan√ßada. K-means √© eficiente e f√°cil de entender, sendo aplicado em uma variedade de contextos, como segmenta√ß√£o de clientes, compress√£o de imagem e reconhecimento de padr√µes. <br>

<b>ii. Self-Organizing Maps (SOM):</b><br>

Os Mapas Auto-organiz√°veis s√£o uma classe especial de redes neurais que visa mapear dados de alta dimens√£o em uma grade bidimensional ou tridimensional de forma topologicamente organizada. A caracter√≠stica distintiva dos SOMs √© a capacidade de preservar as rela√ß√µes espaciais entre os dados durante o processo de treinamento. Cada n√≥ na grade representa um neur√¥nio e est√° associado a um vetor de peso. Durante o treinamento, os neur√¥nios ajustam seus pesos para representar caracter√≠sticas importantes do conjunto de dados. SOMs s√£o frequentemente utilizados para visualiza√ß√£o de dados complexos e redu√ß√£o de dimensionalidade, facilitando a identifica√ß√£o de padr√µes e clusters. <br>

Ambos os algoritmos, K-means e SOM, s√£o fundamentais no aprendizado n√£o supervisionado, fornecendo meios eficazes de explorar a estrutura subjacente nos dados. A escolha entre eles depender√° das caracter√≠sticas espec√≠ficas do problema em quest√£o, como a natureza dos dados, a dimensionalidade e a complexidade das rela√ß√µes a serem identificadas. O K-means √© mais adequado para problemas de clustering simples, enquanto os SOMs s√£o especialmente √∫teis quando a topologia dos dados √© uma considera√ß√£o importante.<br><br>
<b class="maior">Aprendizado por Refor√ßo</b><br><br>
Nesta forma, os algoritmos aprendem atrav√©s da intera√ß√£o cont√≠nua com um ambiente. O agente de aprendizado recebe feedback na forma de recompensas ou penalidades ap√≥s a√ß√µes executadas em determinado contexto. O objetivo do agente √© aprender a tomar decis√µes que maximizem a recompensa ao longo do tempo. O aprendizado por refor√ßo √© frequentemente usado em jogos, rob√≥tica, otimiza√ß√£o e outras √°reas onde as a√ß√µes s√£o sequenciais e t√™m consequ√™ncias a longo prazo.<br><br>

O aprendizado por refor√ßo √© um paradigma no qual um agente interage com um ambiente, toma decis√µes sequenciais e recebe feedback na forma de recompensas ou penalidades. O objetivo √© que o agente aprenda a tomar a√ß√µes que maximizem as recompensas ao longo do tempo. Um algoritmo de aprendizado por refor√ßo not√°vel √© o Q-Learning. <br>

<b>i. Q-Learning: </b> <br>

O Q-Learning √© um algoritmo de aprendizado por refor√ßo que pertence √† classe dos m√©todos de aprendizado de valor. Ele √© particularmente eficaz em ambientes nos quais o agente n√£o possui conhecimento pr√©vio sobre o ambiente e deve aprender por tentativa e erro. O Q-Learning estima a qualidade (ou valor) de cada par estado-a√ß√£o, representado pela fun√ß√£o Q. <br>

O processo de aprendizado envolve a atualiza√ß√£o iterativa dos valores Q com base nas recompensas recebidas pelo agente. O algoritmo utiliza uma f√≥rmula de atualiza√ß√£o que leva em considera√ß√£o a recompensa instant√¢nea, a estimativa do valor m√°ximo futuro (utilizando a fun√ß√£o Q) e um fator de desconto para considerar a import√¢ncia do futuro em rela√ß√£o ao presente. <br>

O Q-Learning √© especialmente aplicado em problemas nos quais o agente pode explorar diferentes a√ß√µes e aprender uma pol√≠tica √≥tima ao longo do tempo. Ele tem sido utilizado em uma variedade de dom√≠nios, desde jogos at√© controle de rob√¥s, e √© uma base para muitos algoritmos mais avan√ßados de aprendizado por refor√ßo. <br>

No processo de treinamento, o Q-Learning permite que o agente aprenda a√ß√µes que resultam em recompensas mais altas, ajustando gradualmente suas estimativas de valores Q. Esse tipo de abordagem √© poderoso em cen√°rios nos quais √© dif√≠cil definir um conjunto de regras expl√≠citas para o agente seguir, permitindo que ele descubra estrat√©gias eficientes por conta pr√≥pria. <br>
        </p>
    </section>

    <section id="classifica">
        <h1>Classifica√ß√£o e Regress√£o</h1>
        <div class="line"></div>
            <div style="text-align: center  !important;">
            <img src="Aprendizado-supervisionada.png"> <br><br>
            </div>
            <p class="classe" style="text-align: justify;">
                As aplica√ß√µes do Aprendizado Supervisionado geralmente se concentram em 2 tipos: problemas de classifica√ß√£o e problemas de regress√£o.

Na classifica√ß√£o, objetiva-se taguear adequadamente os sujeitos de teste em determinada categoria de interesse, e na regress√£o, objetiva-se chegar a um valor num√©rico cont√≠nuo como resultado. <br><br>

<b> i. Extra√ß√£o de Caracter√≠sticas: </b> <br> <br>

A Extra√ß√£o de Caracter√≠sticas √© um processo crucial em problemas de classifica√ß√£o e regress√£o. Consiste em identificar e selecionar as informa√ß√µes mais relevantes dos dados brutos, transformando-os em um formato mais adequado para an√°lise. Este processo ajuda a melhorar a efici√™ncia computacional, reduzir a dimensionalidade e, em muitos casos, aprimorar o desempenho do modelo. M√©todos comuns incluem t√©cnicas estat√≠sticas, transforma√ß√µes matem√°ticas e algoritmos de aprendizado n√£o supervisionado, como An√°lise de Componentes Principais (PCA) para redu√ß√£o de dimensionalidade. <br><br>

<b> ii. Pr√©-processamento: </b> <br> <br>

O Pr√©-processamento de dados √© uma etapa fundamental para garantir a qualidade e efic√°cia dos modelos de classifica√ß√£o e regress√£o. Isso inclui a limpeza de dados (tratamento de valores ausentes e outliers), normaliza√ß√£o (garantindo que as vari√°veis estejam na mesma escala), codifica√ß√£o de vari√°veis categ√≥ricas, e outras t√©cnicas para preparar os dados para o treinamento do modelo. O pr√©-processamento contribui para evitar vieses indesejados, melhorar a interpretabilidade e acelerar o treinamento dos modelos. <br><br>

<b> iii. Overfitting e Underfitting: </b><br><br>

<b> Overfitting: </b> O Overfitting ocorre quando um modelo se ajusta muito bem aos dados de treinamento, capturando n√£o apenas os padr√µes verdadeiros, mas tamb√©m o ru√≠do e as varia√ß√µes aleat√≥rias nos dados. Isso leva a um desempenho sub√≥timo em dados n√£o vistos, pois o modelo se torna excessivamente complexo. Estrat√©gias para lidar com o overfitting incluem a redu√ß√£o da complexidade do modelo, a coleta de mais dados de treinamento ou a aplica√ß√£o de t√©cnicas como regulariza√ß√£o. <br>
<b> Underfitting: </b> O Underfitting, por outro lado, ocorre quando o modelo √© muito simples para capturar as rela√ß√µes nos dados de treinamento. Isso resulta em um desempenho inadequado, pois o modelo n√£o consegue aprender os padr√µes complexos presentes nos dados. Solu√ß√µes para o underfitting incluem a escolha de modelos mais complexos, a coleta de mais dados ou o ajuste de hiperpar√¢metros. <br><br>

O equil√≠brio entre extra√ß√£o de caracter√≠sticas, pr√©-processamento e a gest√£o de overfitting e underfitting desempenha um papel crucial no desenvolvimento de modelos de classifica√ß√£o e regress√£o robustos e generaliz√°veis. A sele√ß√£o cuidadosa dessas t√©cnicas pode melhorar significativamente a capacidade do modelo de aprender padr√µes √∫teis nos dados e realizar previs√µes precisas em novos conjuntos de dados.
        </p>
        
    </section>

   <section id="deep">
        <h1>Redes Neurais e Deep Learning</h1>
        <div class="line"></div>
        
    </section>
    <section id="referencias" class="classe" style="margin-top: 100px;">
        <h1>Refer√™ncias</h1>
        <div class="line"></div>
        <p style="text-align: justify;"><b></b></p>

    </section>
    <br>
    
    <section id="Contato" style="background: linear-gradient(#c1d9d9 0%, #afd6bf 100%);">

        <div class="container contact_1">
            <hr>
            <img src="fotolts_compressed_Easy-Resize.com.jpg" style="width: 250px;" class="img-responsive img-circle col-lg-3 col-md-3 col-sm-3 col-xs-4">
            <div style="margin-top: 100px;">
            <h3 style="font-family: cursive;" >Jh√©ssica Isabel Coelho Souza</h3><br>
            <h3 style="font-family: cursive;">Matr√≠cula: 170146031</h3><br>
            <a href="mailto:jhessicaisabel.eng@gmail.com?Subject=Hello">
                
                <span style="font-size: 30px;">üìß</span>&nbsp;&nbsp;<h3>jhessicaisabel.eng@gmail.com</h3>
            </a>

            <br>
            <br>

            <a href="https://github.com/Jhessss" target="_blank">
                <svg xmlns="http://www.w3.org/2000/svg" height="32" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/>
                  </svg>
                <i class="octicon octicon-mark-github"></i>&nbsp;&nbsp;<h3>Github</h3>
            </a>
        </div>

        </div>

    </section>
  

</body>

</html>